{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Refugee Matching\n",
    "# Simulations\n",
    "\n",
    "This notebook replicates the simulations performed by Andersson, Ehlers and Martinello (2018). All the necessary documentation, requirements and dependecies should be documented in the package. If you have any comment, spot any bug or some documentation is missing, please let us know.\n",
    "\n",
    "We proceed in three steps. First, we assess the performance of ``aem`` in case of misclassification error in the locality preference partitions. Second, we examine the performance of the algorithm if yearly quotas are split into monthly, trimestral, or semestral subperiods. Finally, we provide some supporting evidence for our conjecture relative to Theorem 2 in that paper: That is, at any matching $x(k)$ selected by our proposed mechanism, envy is always bounded by a single acceptable asylum seeker *and* a single unacceptable asylum seeker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd \n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sensitivity to misclassification error in the locality partitions\n",
    "\n",
    "In this section we focus on highlighting the dynamic properties of the algorithm while allowing for imperfect inputs to the model. In the paper, we prove that our proposed mechanism guarantees an efficient an fair allocation at every processed asylum seeker $k$, given that the ``scores`` matrix (the locality-specific partitions of acceptable and unacceptable asylum seekers) is observed. \n",
    "\n",
    "In practice, the ex-post match quality (and thus the **scoring matrix**) needs to be estimated. As any estimation necessarily involves some estimation error, this sections shows that even with mismeasures locality-specific partitions, our algorithm substantially outperforms naive, uninformed allocation mechanisms. \n",
    "\n",
    "Our dynamic measures of **fairness** are \n",
    "1) The proportion of localities envying at least another municipality in the sample by 1 refugee\n",
    "2) The proportion of localities envying at least another municipality in the sample by more that a fourth of the average assigned refugees per locality. \n",
    "Theorem 1 and 2 show that if we observed the true scoring matrix, both measures would be equal to zero under our allocation mechanism. \n",
    "\n",
    "Our dynamic measure of **efficiency** is the proportion of *demanded* refugees that are assigned to a municipality that considers them non-demanded. That is, the proportion of potentially good matches between a refugee and a locality that instead are realized as bad matches due to an imperfect allocation. Reallocating (ex-post) such a refugee to a demanding municipality would be a Pareto-improvement. As such, the higher this measure, the more inefficient the llocation can be considered. With perfect knowledge about the scoring matrix, our mechanism ensures that this measure is always equal to zero.\n",
    "\n",
    "In order to assess the gains in fairness and efficiency due to the algorithm, we simulate random refugee flows calibrated to match the US and the Swedish situation. We then scramble the real scoring matrix with an increasing amount of misclassification error, and compare the resulting assignment with that of a naive sequential algorithm. \n",
    "\n",
    "Note that empirically the distiction betwen demanded and non-demanded asylum seekers creates three types of refugees:\n",
    "- **Refugees $\\underline{D}$:** These refugees are *non-demanded*, meaning that no locality finds them acceptable\n",
    "- **Refugees $\\overline{D}$:** These refugees are a special case of *over-demanded* refugees, such that **all** localities find them acceptable\n",
    "- **Refugees $D$:** These refugees can be either *demanded* or *over-demanded*. At least one locality finds them acceptable, and at least one locality finds them *non-acceptable*\n",
    "\n",
    "As we argue for in the paper, the algorithm works best when the proportion of refugees that exhibit synergies across localitites $D$ (i.e., those that integrate in some localities but not others) is highest. When calibrating the asylum seeker flows we put ourselves in a worst-case scenario situation by minimizing the number of this type of refugees. That is, the proportion of refugees of type $\\overline{D}$  in the refugee flow is given by the lowest amount of refugees finding employment within 3 months (US data) and 3 years (Swedish data) across localities. The proportion of refugees of type $\\underline{D}$ is given by the highest amount of refugee not finding employment across localities in the same time period.\n",
    "\n",
    "We begin by setting the simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('us', (50, [0.34, 0.39, 0.5])), ('swe', (21, [0.28, 0.45, 0.5]))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# set general parameters\n",
    "n_simulations = 1000\n",
    "n_refugees = 1000\n",
    "\n",
    "# set country-specific parameters: n_localities, [AA, NA, autocorrelation]\n",
    "country_properties = {}\n",
    "country_properties['us'] =  50, [0.34, 0.39, 0.5] ## AA: Science paper\n",
    "country_properties['swe'] = 21, [0.28, 0.45, 0.5] ## AA: 3-years employment rate of 2013 refugee wave\n",
    "\n",
    "# (alternative) threshold for second envy measure \n",
    "envy_limit_fraction = 0.25 \n",
    "\n",
    "# list of misclassification errors on which to run AEM\n",
    "errorlist = [0, 10, 25, 40]\n",
    "\n",
    "country_properties.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(errorlist).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-56defb06f5cb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-56defb06f5cb>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    from start_time = time.time()\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from dynamic_refugee_matching.assignment import assign\n",
    "import dynamic_refugee_matching.flowgen as flg\n",
    "\n",
    "start_time = time.time()\n",
    "# Simulation\n",
    "output = np.zeros((n_refugees, len(sim_types)*3))\n",
    "\n",
    "# Dictionaries initialization\n",
    "assignments = {}\n",
    "mis_dem = {}\n",
    "\n",
    "for country in ['swe','us']:\n",
    "    simint = round(n_simulations/10)\n",
    "    for sim in np.arange(n_simulations):\n",
    "        if sim%simint==0:\n",
    "            print(\"Country:\", country, \"; Simulation\", sim, \"of\", n_simulations, \n",
    "                  \". Elapsed time:\", f_writetime(time.time() - start_time))\n",
    "\n",
    "        # simulate demand/refugee flow\n",
    "        demand_matrix = af.simulate_matrix(n_refugees, n_municipalities[country], \n",
    "                                           p_nond = refflow[country][0], \n",
    "                                           p_over = refflow[country][1], \n",
    "                                           autocorrelation = refflow[country][2]\n",
    "                                          )\n",
    "\n",
    "        n_demanded_refugees = np.cumsum(np.amax(demand_matrix, axis=1))\n",
    "\n",
    "        assignments['sequential'] = af.assign_seq(demand_matrix)\n",
    "        # Initialize misallocated count\n",
    "        mis_dem['sequential'] = 0\n",
    "        for error in errorslist:\n",
    "            assignments['err_{0}'.format(error)] = af.assign(af.add_error(demand_matrix, error))\n",
    "            # Initialize misallocated count\n",
    "            mis_dem['err_{0}'.format(error)] = 0\n",
    "\n",
    "        # foreach refugee\n",
    "        for k in np.arange(n_refugees):\n",
    "            for val, atype in enumerate(sim_types):\n",
    "                # update misallocated count\n",
    "                if (np.sum(demand_matrix[k])>0) and (np.sum(assignments[atype].assignment[k][:]*demand_matrix[k][:])==0):\n",
    "                    mis_dem[atype] += 1\n",
    "                # calculate measures\n",
    "                max_envy = np.amax(assignments[atype].get_envy(refugee=k,real_acceptance=demand_matrix), axis=1)\n",
    "                envy0 = np.mean((max_envy>0))\n",
    "                envy1 = np.mean((max_envy>=envy_limit))\n",
    "                if n_demanded_refugees[k]>0:\n",
    "                    effic = mis_dem[atype]/n_demanded_refugees[k]\n",
    "                else:\n",
    "                    effic = 0\n",
    "\n",
    "                # Update averages\n",
    "                output[k,val*3 + 0] = (output[k,val*3 + 0]*(sim) + envy0)/(sim+1)\n",
    "                output[k,val*3 + 1] = (output[k,val*3 + 1]*(sim) + envy1)/(sim+1)\n",
    "                output[k,val*3 + 2] = (output[k,val*3 + 2]*(sim) + effic)/(sim+1)\n",
    "\n",
    "    nameslist = []\n",
    "    for atype in sim_types:\n",
    "        nameslist.append('envy0_'+atype)\n",
    "        nameslist.append('envy1_'+atype)\n",
    "        nameslist.append('effic_'+atype)\n",
    "    if country == 'swe':\n",
    "        simerror_swe = pd.DataFrame(output, columns=nameslist)\n",
    "        simerror_swe.to_pickle(\"data/simerror_swe\")\n",
    "    if country == 'us':\n",
    "        simerror_us = pd.DataFrame(output, columns=nameslist)\n",
    "        simerror_us.to_pickle(\"data/simerror_us\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('Total running time: ', f_writetime(elapsed_time))\n",
    "# Save running time\n",
    "f = open('timers/misclassification.txt','a')\n",
    "f.write(\n",
    "    'Date: ' + str(datetime.date.today()) + '\\n' +\n",
    "    'Parameters: ' + '\\n' + \n",
    "    '  - # simulations: ' + str(n_simulations) + '\\n'\n",
    "    '  - # refugees   : ' + str(n_refugees) + '\\n'\n",
    "    '  - # localities : ' + str(n_municipalities) + '\\n'\n",
    "    'Total running time: ' + f_writetime(elapsed_time) + '\\n\\n'\n",
    ")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
